# ðŸ“• HNG Stage 3 DevOps Runbook

This document details the alerts generated by the `alert_watcher` service and the corresponding actions operators should take.

| Alert Type                                 | Description                                                                                                                                                                    | Operator Action                                                                                                                                                                                                                                                                                                                                                                                                                                      | Expected Recovery                                                                                                                |
| :----------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- |
| **POOL FAILOVER DETECTED** (Blue -> Green) | Traffic has switched from the primary (Blue) to the backup (Green) pool, indicating a failure in Blue or a manual toggle.                                                      | 1. **CONFIRM FAILURE:** Check the direct health endpoint of the old primary (e.g., `http://<IP>:8081/healthz`). 2. **INSPECT LOGS:** Review the logs of the failed container (`app_blue`) for crash reports or repeated 5xx errors. 3. **REMEDIATE:** If necessary, restart the failed container (`docker restart app_blue`).                                                                                                                        | Once the primary (Blue) returns to a healthy state and serves requests successfully, Nginx will automatically fail back to Blue. |
| **POOL FAILOVER DETECTED** (Green -> Blue) | Traffic has switched back to the Primary (Blue) pool. This typically signifies **Recovery**.                                                                                   | 1. **CONFIRM RECOVERY:** Verify traffic is stable on Blue via the main endpoint (`http://<IP>:8080/version`). 2. **NO ACTION** required unless the switch-back is unexpected.                                                                                                                                                                                                                                                                        | The system has self-healed or the failed service has been manually remediated.                                                   |
| **HIGH ERROR RATE DETECTED**               | The rate of upstream 5xx errors (errors returned by the application containers) has exceeded the configured threshold (e.g., 2%) over the sliding window (e.g., 200 requests). | 1. **IDENTIFY POOL:** Check the `pool` field in the alert (e.g., `Pool: BLUE`). 2. **INSPECT LOGS:** Immediately inspect the logs of the identified upstream container (`app_blue` or `app_green`) for application-level errors. 3. **ISOLATE:** If the current primary is failing, initiate a **Manual Toggle** by updating the `ACTIVE_POOL` environment variable and reloading Nginx (`nginx -s reload`) to switch traffic to the working backup. | The error rate must drop below the threshold (e.g., <2%) over the window size (200 requests).                                    |

### Maintenance Mode (Alert Suppression)

To suppress alerts during planned deployments or maintenance (e.g., during a manual pool toggle):

- **Option 1 (Soft):** Rely on the **`ALERT_COOLDOWN_SEC`** setting. Set the cooldown high (e.g., 3600 seconds) before the maintenance window begins.
- **Option 2 (Code Level):** The operator can temporarily set a `MAINTENANCE_MODE=true` environment variable in the `alert_watcher` service, which would be checked at the start of the `post_to_slack` function.

---

## ðŸ“‹ Final Requirements Checklist

| Requirement                  | Status       | Notes                                                                                      |
| :--------------------------- | :----------- | :----------------------------------------------------------------------------------------- |
| Nginx custom log format      | **COMPLETE** | Uses `json_log` to capture `pool`, `release`, `upstream_status`, etc.                      |
| Python log-watcher service   | **COMPLETE** | `watcher.py` handles tailing, parsing, rolling window, and state.                          |
| Failover alert (Blue/Green)  | **COMPLETE** | Handled by `check_failover` when `current_pool` changes.                                   |
| Error-rate alert (>2% 5xx)   | **COMPLETE** | Handled by `analyze_error_rate` using `deque` for rolling window.                          |
| Alert cooldown/rate limiting | **COMPLETE** | Implemented using `ALERT_COOLDOWN_SEC` and `last_alert_time`.                              |
| `.env` variables             | **COMPLETE** | All 5 required variables (`SLACK_WEBHOOK_URL`, `ERROR_RATE_THRESHOLD`, etc.) are included. |
| `runbook.md` provided        | **COMPLETE** | Defines meaning and actions for Failover and Error-Rate alerts.                            |

---
